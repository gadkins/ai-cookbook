{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Detecting PII in LLM-Powered Chat Applications**\n",
        "\n",
        "by [Grayson Adkins](https://twitter.com/GraysonAdkins), updated April 17, 2024  \n",
        "\n",
        "This notebook demonstrates how to evaluate user prompts and LLM responses for personally identifiable infromation (PII) such as contact information, financial or banking info, digital identifieers, job related data, or other sensitive personal information.  \n",
        "\n",
        "We use the [`bigcode/starpii`](https://huggingface.co/bigcode/starpii) PII detection model available on Hugging Face plus LangChain for crafting prompt templates and TruLens for running evaluation and visualizing results.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/drive/1hDIIgKUJVoxm_ymglD3w_Z7IQasRwyqA?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "## Attribution\n",
        "\n",
        " This notebook builds on [examples provided by TruLens](https://github.com/truera/trulens/tree/main/trulens_eval/examples).  \n",
        "\n",
        "\n",
        "## Disclaimer\n",
        "\n",
        "Both TruLens and LangChain are new frameworks with rapidly changing interfaces. I found several deprecated or broken features that I had to resolve while working on this notebook. Be advised that you may similarly find issues with the code here, due to those dependencies."
      ],
      "metadata": {
        "id": "iIg0dHk5e9px"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "wj5KEUkmf56Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIzB1NyBe7Mj",
        "outputId": "be3ef653-4c43-4374-aa0d-f5fa548e6b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU trulens_eval langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r-Qoi2Djbf2",
        "outputId": "f020462f-34e4-4381-8657-6d62776a6b5c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/309.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.7/309.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "\n",
        "# # Load OPENAI_API_KEY from local .env file\n",
        "# load_dotenv(find_dotenv())\n",
        "\n",
        "# Or set it like this\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
        "\n",
        "## Print key to check\n",
        "# print(os.environ[\"OPENAI_API_KEY\"])"
      ],
      "metadata": {
        "id": "5S_JoVxwgIzZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up TruLens"
      ],
      "metadata": {
        "id": "znJUyzSjnxPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import Feedback\n",
        "from trulens_eval import OpenAI as trulens_provider_openai\n",
        "from trulens_eval import Tru\n",
        "\n",
        "tru = Tru()\n",
        "tru.reset_database()"
      ],
      "metadata": {
        "id": "9AF_bf-Jgm7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports from langchain to build app. You may need to install langchain first\n",
        "# with the following:\n",
        "# ! pip install langchain>=0.0.170\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts.chat import HumanMessagePromptTemplate, ChatPromptTemplate"
      ],
      "metadata": {
        "id": "Xlm6IKx8jCLV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        template=\n",
        "        \"Provide a helpful response with relevant background information for the following: {prompt}\",\n",
        "        input_variables=[\"prompt\"],\n",
        "    )\n",
        ")\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages([full_prompt])\n",
        "\n",
        "llm = OpenAI(temperature=0.9, max_tokens=128)\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=chat_prompt_template, verbose=True)"
      ],
      "metadata": {
        "id": "dt4qOEapjFFh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_input = 'Sam Altman is the CEO at OpenAI, and uses the password: password1234 .'"
      ],
      "metadata": {
        "id": "MbyNBMLpjlYJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TruLens feedback functions\n",
        "\n",
        "This feedback function includes chain of thought reasoning."
      ],
      "metadata": {
        "id": "74GczfpIj3ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval.feedback.provider.hugs import Huggingface\n",
        "\n",
        "# Hugging Face based feedback function collection class\n",
        "hf_provider = Huggingface()"
      ],
      "metadata": {
        "id": "79OnGNotkIsz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a pii_detection feedback function using HuggingFace.\n",
        "# By default this will check language match on the main app input\n",
        "f_pii_detection = Feedback(hf_provider.pii_detection_with_cot_reasons).on_input()"
      ],
      "metadata": {
        "id": "BH-Xndzmj65c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create TruLens recorder"
      ],
      "metadata": {
        "id": "KIPvsmvPlLPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tru_recorder = TruChain(chain,\n",
        "    app_id='Chain1_ChatApplication',\n",
        "    feedbacks=[f_pii_detection])"
      ],
      "metadata": {
        "id": "tKYVraO8lOOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execute eval"
      ],
      "metadata": {
        "id": "B3if48Ghlitm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tru_recorder as recording:\n",
        "    llm_response = chain(prompt_input)\n",
        "\n",
        "display(llm_response)"
      ],
      "metadata": {
        "id": "5OW-j_9qlPrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display results"
      ],
      "metadata": {
        "id": "467BwG_-llOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
        "\n",
        "# Make it a little easier to read\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "records[[\"input\", \"output\"] + feedback]"
      ],
      "metadata": {
        "id": "4M5wGwLklbNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tru.run_dashboard() # open a local streamlit app to explore\n",
        "\n",
        "# tru.stop_dashboard() # stop if needed"
      ],
      "metadata": {
        "id": "8jCe5d-ilqnl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
